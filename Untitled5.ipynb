{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iETpa0otFnXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f27c027-9862-4d6c-8bde-27e814e661f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n",
            "Библиотеки успешно импортированы!\n"
          ]
        }
      ],
      "source": [
        "# Установка необходимых библиотек\n",
        "!pip install pandas numpy scikit-learn catboost\n",
        "\n",
        "# Импорт библиотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Библиотеки успешно импортированы!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    print(\"Загрузка данных...\")\n",
        "\n",
        "    try:\n",
        "        # Основные данные\n",
        "        train = pd.read_csv('/content/data/train.csv', sep=',', quotechar='\"')\n",
        "        test = pd.read_csv('/content/data/test.csv', sep=',', quotechar='\"')\n",
        "\n",
        "        # Метаданные\n",
        "        books = pd.read_csv('/content/data/books.csv', sep=',', quotechar='\"')\n",
        "        users = pd.read_csv('/content/data/users.csv', sep=',', quotechar='\"')\n",
        "        genres = pd.read_csv('/content/data/genres.csv', sep=',', quotechar='\"')\n",
        "        book_genres = pd.read_csv('/content/data/book_genres.csv', sep=',', quotechar='\"')\n",
        "        book_descriptions = pd.read_csv('/content/data/book_descriptions.csv', sep=',', quotechar='\"')\n",
        "\n",
        "        print(\"Данные успешно загружены!\")\n",
        "        print(f\"Train: {train.shape}\")\n",
        "        print(f\"Test: {test.shape}\")\n",
        "        print(f\"Books: {books.shape}\")\n",
        "        print(f\"Users: {users.shape}\")\n",
        "\n",
        "        return train, test, books, users, genres, book_genres, book_descriptions\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Ошибка загрузки файлов: {e}\")\n",
        "        print(\"Убедитесь, что все файлы загружены в папку /content/data/\")\n",
        "        return None\n",
        "\n",
        "# Загружаем данные\n",
        "data = load_data()\n",
        "if data:\n",
        "    train, test, books, users, genres, book_genres, book_descriptions = data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntFYLKfyM_gn",
        "outputId": "ab803646-7319-4fbe-fdba-59cd1972e21d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка данных...\n",
            "Данные успешно загружены!\n",
            "Train: (268581, 5)\n",
            "Test: (2894, 2)\n",
            "Books: (50490, 8)\n",
            "Users: (7277, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(train, test, books, users, genres, book_genres, book_descriptions):\n",
        "    print(\"Предобработка данных...\")\n",
        "\n",
        "    # Создаем копии данных\n",
        "    train_processed = train.copy()\n",
        "    test_processed = test.copy()\n",
        "    books_processed = books.copy()\n",
        "    users_processed = users.copy()\n",
        "\n",
        "    # Оставляем только прочитанные книги для обучения\n",
        "    train_processed = train_processed[train_processed['has_read'] == 1].copy()\n",
        "    print(f\"После фильтрации прочитанных книг: {train_processed.shape}\")\n",
        "\n",
        "    # Преобразование временных меток\n",
        "    train_processed['timestamp'] = pd.to_datetime(train_processed['timestamp'])\n",
        "    train_processed['year'] = train_processed['timestamp'].dt.year\n",
        "    train_processed['month'] = train_processed['timestamp'].dt.month\n",
        "    train_processed['day'] = train_processed['timestamp'].dt.day\n",
        "    train_processed['dayofweek'] = train_processed['timestamp'].dt.dayofweek\n",
        "\n",
        "    # Обработка пропущенных значений в books\n",
        "    books_processed['publication_year'] = books_processed['publication_year'].fillna(books_processed['publication_year'].median())\n",
        "    books_processed['language'] = books_processed['language'].fillna(books_processed['language'].mode()[0] if not books_processed['language'].mode().empty else 0)\n",
        "    books_processed['publisher'] = books_processed['publisher'].fillna(books_processed['publisher'].mode()[0] if not books_processed['publisher'].mode().empty else 0)\n",
        "\n",
        "    # Обработка users\n",
        "    users_processed['age'] = users_processed['age'].fillna(users_processed['age'].median())\n",
        "    users_processed['gender'] = users_processed['gender'].fillna(users_processed['gender'].mode()[0] if not users_processed['gender'].mode().empty else 0)\n",
        "\n",
        "    print(\"Предобработка завершена!\")\n",
        "    return train_processed, test_processed, books_processed, users_processed\n",
        "\n",
        "# Применяем предобработку\n",
        "train_proc, test_proc, books_proc, users_proc = preprocess_data(\n",
        "    train, test, books, users, genres, book_genres, book_descriptions\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOEJq4IYNNQ7",
        "outputId": "8a607fa8-7be0-4b91-f377-f665c8574cda"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предобработка данных...\n",
            "После фильтрации прочитанных книг: (156179, 5)\n",
            "Предобработка завершена!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_features(train, users):\n",
        "    print(\"Создание признаков пользователей...\")\n",
        "\n",
        "    # Статистики по пользователям из train\n",
        "    user_stats = train.groupby('user_id').agg({\n",
        "        'rating': ['mean', 'std', 'min', 'max', 'count'],\n",
        "        'book_id': 'nunique',\n",
        "        'year': ['min', 'max', 'nunique'],\n",
        "        'month': 'nunique',\n",
        "        'dayofweek': 'nunique'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Выравниваем multi-index columns\n",
        "    user_stats.columns = ['user_id'] + [f'user_{col[0]}_{col[1]}' for col in user_stats.columns[1:]]\n",
        "\n",
        "    # Объединяем с метаданными пользователей\n",
        "    user_features = pd.merge(users, user_stats, on='user_id', how='left')\n",
        "\n",
        "    # Заполняем пропуски для пользователей без истории\n",
        "    numeric_cols = user_features.select_dtypes(include=[np.number]).columns\n",
        "    user_features[numeric_cols] = user_features[numeric_cols].fillna(user_features[numeric_cols].median())\n",
        "\n",
        "    print(f\"Признаки пользователей созданы: {user_features.shape}\")\n",
        "    return user_features\n",
        "\n",
        "# Создаем признаки пользователей\n",
        "user_features = create_user_features(train_proc, users_proc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AdmVPW2NORH",
        "outputId": "40d20c19-b785-4883-b93a-e9ee8514bee7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создание признаков пользователей...\n",
            "Признаки пользователей созданы: (7277, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_book_features(train, books, book_genres, book_descriptions):\n",
        "    print(\"Создание признаков книг...\")\n",
        "\n",
        "    # Статистики по книгам из train\n",
        "    book_stats = train.groupby('book_id').agg({\n",
        "        'rating': ['mean', 'std', 'min', 'max', 'count'],\n",
        "        'user_id': 'nunique',\n",
        "        'year': ['min', 'max'],\n",
        "        'month': 'nunique'\n",
        "    }).reset_index()\n",
        "\n",
        "    book_stats.columns = ['book_id'] + [f'book_{col[0]}_{col[1]}' for col in book_stats.columns[1:]]\n",
        "\n",
        "    # Признаки жанров\n",
        "    book_genre_counts = book_genres.groupby('book_id').size().reset_index(name='book_genre_count')\n",
        "    book_main_genre = book_genres.groupby('book_id')['genre_id'].first().reset_index()\n",
        "    book_main_genre.columns = ['book_id', 'book_main_genre']\n",
        "\n",
        "    # Объединяем все признаки книг\n",
        "    book_features = pd.merge(books, book_stats, on='book_id', how='left')\n",
        "    book_features = pd.merge(book_features, book_genre_counts, on='book_id', how='left')\n",
        "    book_features = pd.merge(book_features, book_main_genre, on='book_id', how='left')\n",
        "\n",
        "    # Заполняем пропуски\n",
        "    book_features['book_genre_count'] = book_features['book_genre_count'].fillna(0)\n",
        "    book_main_genre_mode = book_features['book_main_genre'].mode()\n",
        "    book_features['book_main_genre'] = book_features['book_main_genre'].fillna(book_main_genre_mode[0] if not book_main_genre_mode.empty else 0)\n",
        "\n",
        "    numeric_cols = book_features.select_dtypes(include=[np.number]).columns\n",
        "    book_features[numeric_cols] = book_features[numeric_cols].fillna(book_features[numeric_cols].median())\n",
        "\n",
        "    print(f\"Признаки книг созданы: {book_features.shape}\")\n",
        "    return book_features\n",
        "\n",
        "# Создаем признаки книг\n",
        "book_features = create_book_features(train_proc, books_proc, book_genres, book_descriptions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMc0g6hmNRka",
        "outputId": "132eff9c-5349-4865-9ed8-0d345095da7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создание признаков книг...\n",
            "Признаки книг созданы: (50490, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature_matrix(train, test, user_features, book_features):\n",
        "    print(\"Создание матрицы признаков...\")\n",
        "\n",
        "    # Обучающая выборка\n",
        "    X_train = pd.merge(train[['user_id', 'book_id', 'rating']], user_features, on='user_id', how='left')\n",
        "    X_train = pd.merge(X_train, book_features, on='book_id', how='left')\n",
        "\n",
        "    # Тестовая выборка\n",
        "    X_test = pd.merge(test[['user_id', 'book_id']], user_features, on='user_id', how='left')\n",
        "    X_test = pd.merge(X_test, book_features, on='book_id', how='left')\n",
        "\n",
        "    # Сохраняем идентификаторы для submission\n",
        "    train_ids = X_train[['user_id', 'book_id']].copy()\n",
        "    test_ids = X_test[['user_id', 'book_id']].copy()\n",
        "\n",
        "    # Удаляем исходные колонки\n",
        "    columns_to_drop = ['user_id', 'book_id', 'title', 'author_name']\n",
        "\n",
        "    X_train = X_train.drop(columns=[col for col in columns_to_drop if col in X_train.columns])\n",
        "    X_test = X_test.drop(columns=[col for col in columns_to_drop if col in X_test.columns])\n",
        "\n",
        "    y_train = X_train['rating']\n",
        "    X_train = X_train.drop('rating', axis=1)\n",
        "\n",
        "    # Выравниваем колонки\n",
        "    common_columns = X_train.columns.intersection(X_test.columns)\n",
        "    X_train = X_train[common_columns]\n",
        "    X_test = X_test[common_columns]\n",
        "\n",
        "    print(f\"Обучающая выборка: {X_train.shape}\")\n",
        "    print(f\"Тестовая выборка: {X_test.shape}\")\n",
        "\n",
        "    return X_train, y_train, X_test, train_ids, test_ids\n",
        "\n",
        "# Создаем матрицу признаков\n",
        "X_train, y_train, X_test, train_ids, test_ids = create_feature_matrix(\n",
        "    train_proc, test_proc, user_features, book_features\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6lOhsnONUjf",
        "outputId": "10c280a0-8f48-41d7-b11c-ca2ee9b02364"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создание матрицы признаков...\n",
            "Обучающая выборка: (156189, 29)\n",
            "Тестовая выборка: (2894, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(X_train, y_train):\n",
        "    print(\"Валидация модели...\")\n",
        "\n",
        "    # Разделяем данные на train/validation\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=42, stratify=pd.cut(y_train, bins=5)\n",
        "    )\n",
        "\n",
        "    # Определяем категориальные признаки\n",
        "    cat_features = list(X_tr.select_dtypes(include=['object', 'category']).columns)\n",
        "    print(f\"Категориальные признаки: {cat_features}\")\n",
        "\n",
        "    # Обучаем модель с валидацией\n",
        "    model = CatBoostRegressor(\n",
        "        iterations=500,\n",
        "        learning_rate=0.1,\n",
        "        depth=6,\n",
        "        random_seed=42,\n",
        "        verbose=100,\n",
        "        early_stopping_rounds=50\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=(X_val, y_val),\n",
        "        cat_features=cat_features\n",
        "    )\n",
        "\n",
        "    # Предсказания на валидации\n",
        "    val_pred = model.predict(X_val)\n",
        "    val_pred = np.clip(val_pred, 0, 10)\n",
        "\n",
        "    # Метрики\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
        "    mae = mean_absolute_error(y_val, val_pred)\n",
        "\n",
        "    # Расчет итогового балла\n",
        "    normalized_rmse = rmse / 10\n",
        "    normalized_mae = mae / 10\n",
        "    score = 1 - (normalized_rmse + normalized_mae) / 2\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"РЕЗУЛЬТАТЫ ВАЛИДАЦИИ:\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"Score: {score:.4f}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    return model, rmse, mae, score\n",
        "\n",
        "# Проводим валидацию\n",
        "model_val, rmse, mae, score = validate_model(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocNA9Ur_NYsD",
        "outputId": "024a5bad-59e6-4739-ecd8-5779e80f3ed1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Валидация модели...\n",
            "Категориальные признаки: []\n",
            "0:\tlearn: 2.8346815\ttest: 2.8307879\tbest: 2.8307879 (0)\ttotal: 78ms\tremaining: 38.9s\n",
            "100:\tlearn: 2.0529589\ttest: 2.0496815\tbest: 2.0496815 (100)\ttotal: 2.75s\tremaining: 10.9s\n",
            "200:\tlearn: 2.0248983\ttest: 2.0422187\tbest: 2.0422187 (200)\ttotal: 6.77s\tremaining: 10.1s\n",
            "300:\tlearn: 2.0028157\ttest: 2.0393089\tbest: 2.0393089 (300)\ttotal: 9.39s\tremaining: 6.21s\n",
            "400:\tlearn: 1.9834207\ttest: 2.0384171\tbest: 2.0382444 (392)\ttotal: 12s\tremaining: 2.95s\n",
            "Stopped by overfitting detector  (50 iterations wait)\n",
            "\n",
            "bestTest = 2.038244389\n",
            "bestIteration = 392\n",
            "\n",
            "Shrink model to first 393 iterations.\n",
            "\n",
            "==================================================\n",
            "РЕЗУЛЬТАТЫ ВАЛИДАЦИИ:\n",
            "RMSE: 2.0378\n",
            "MAE: 1.3230\n",
            "Score: 0.8320\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_final_model(X_train, y_train):\n",
        "    print(\"Обучение финальной модели на всех данных...\")\n",
        "\n",
        "    # Определяем категориальные признаки\n",
        "    cat_features = list(X_train.select_dtypes(include=['object', 'category']).columns)\n",
        "\n",
        "    # Финальная модель\n",
        "    model_final = CatBoostRegressor(\n",
        "        iterations=1000,\n",
        "        learning_rate=0.1,\n",
        "        depth=6,\n",
        "        random_seed=42,\n",
        "        verbose=100,\n",
        "        early_stopping_rounds=50\n",
        "    )\n",
        "\n",
        "    model_final.fit(\n",
        "        X_train, y_train,\n",
        "        cat_features=cat_features\n",
        "    )\n",
        "\n",
        "    print(\"Финальная модель обучена!\")\n",
        "    return model_final\n",
        "\n",
        "# Обучаем финальную модель\n",
        "final_model = train_final_model(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD1gMU2_NeSQ",
        "outputId": "b83d2d7e-2713-459b-96e8-77c4eb665bab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение финальной модели на всех данных...\n",
            "0:\tlearn: 2.8340847\ttotal: 36.1ms\tremaining: 36.1s\n",
            "100:\tlearn: 2.0504953\ttotal: 3.23s\tremaining: 28.8s\n",
            "200:\tlearn: 2.0255488\ttotal: 7.83s\tremaining: 31.1s\n",
            "300:\tlearn: 2.0073773\ttotal: 12s\tremaining: 27.9s\n",
            "400:\tlearn: 1.9918279\ttotal: 15.5s\tremaining: 23.2s\n",
            "500:\tlearn: 1.9779762\ttotal: 20s\tremaining: 19.9s\n",
            "600:\tlearn: 1.9648786\ttotal: 23.1s\tremaining: 15.3s\n",
            "700:\tlearn: 1.9519892\ttotal: 26.3s\tremaining: 11.2s\n",
            "800:\tlearn: 1.9397532\ttotal: 29.6s\tremaining: 7.36s\n",
            "900:\tlearn: 1.9292020\ttotal: 34s\tremaining: 3.73s\n",
            "999:\tlearn: 1.9189836\ttotal: 37.4s\tremaining: 0us\n",
            "Финальная модель обучена!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model, X_test, test_ids):\n",
        "    print(\"Создание предсказаний...\")\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Ограничиваем предсказания диапазоном [0, 10]\n",
        "    predictions = np.clip(predictions, 0, 10)\n",
        "\n",
        "    # Создаем submission файл\n",
        "    submission = test_ids.copy()\n",
        "    submission['rating_predict'] = predictions\n",
        "\n",
        "    # Статистика предсказаний\n",
        "    print(\"\\nСтатистика предсказаний:\")\n",
        "    print(f\"Min: {submission['rating_predict'].min():.2f}\")\n",
        "    print(f\"Max: {submission['rating_predict'].max():.2f}\")\n",
        "    print(f\"Mean: {submission['rating_predict'].mean():.2f}\")\n",
        "    print(f\"Std: {submission['rating_predict'].std():.2f}\")\n",
        "\n",
        "    return submission\n",
        "\n",
        "# Создаем предсказания\n",
        "submission = make_predictions(final_model, X_test, test_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MogrRu1HNken",
        "outputId": "da2bf802-edd2-473c-f813-65ba6dbd9ada"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создание предсказаний...\n",
            "\n",
            "Статистика предсказаний:\n",
            "Min: 0.00\n",
            "Max: 10.00\n",
            "Mean: 8.01\n",
            "Std: 1.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_results(submission, model, X_train):\n",
        "    print(\"Сохранение результатов...\")\n",
        "\n",
        "    # Сохраняем submission файл\n",
        "    submission.to_csv('submission.csv', index=False)\n",
        "    print(\"Файл submission.csv сохранен!\")\n",
        "\n",
        "    # Сохраняем важность признаков\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X_train.columns,\n",
        "        'importance': model.get_feature_importance()\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\nТоп-10 важных признаков:\")\n",
        "    print(feature_importance.head(10))\n",
        "\n",
        "    # Сохраняем важность признаков в файл\n",
        "    feature_importance.to_csv('feature_importance.csv', index=False)\n",
        "    print(\"Файл feature_importance.csv сохранен!\")\n",
        "\n",
        "    return feature_importance\n",
        "\n",
        "# Сохраняем результаты\n",
        "feature_importance = save_results(submission, final_model, X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ssvH_wRNlRz",
        "outputId": "05be70d7-cd1c-43c4-d939-c1cd9864c366"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сохранение результатов...\n",
            "Файл submission.csv сохранен!\n",
            "\n",
            "Топ-10 важных признаков:\n",
            "              feature  importance\n",
            "2    user_rating_mean   30.814376\n",
            "18   book_rating_mean   22.700650\n",
            "19    book_rating_std   10.604049\n",
            "3     user_rating_std    9.575801\n",
            "20    book_rating_min    4.615054\n",
            "13          author_id    2.137611\n",
            "17         avg_rating    1.855637\n",
            "22  book_rating_count    1.855049\n",
            "1                 age    1.660254\n",
            "21    book_rating_max    1.657314\n",
            "Файл feature_importance.csv сохранен!\n"
          ]
        }
      ]
    }
  ]
}